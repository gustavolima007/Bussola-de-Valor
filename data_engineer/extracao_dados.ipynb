{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d56c0ba",
   "metadata": {},
   "source": [
    "# Extra√ß√£o de dados para o projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e53cf",
   "metadata": {},
   "source": [
    "## Extraindo todas empresas do Brasil da categoria BESST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- PASSO 1: CONFIGURA√á√ÉO DOS SETORES-ALVO ---\n",
    "setores_alvo = [\n",
    "    \"Finance\",\n",
    "    \"Utilities\",\n",
    "    \"Communications\",\n",
    "    \"Industrial Services\"\n",
    "]\n",
    "\n",
    "# --- FUN√á√ÉO PRINCIPAL COM A L√ìGICA FINAL ---\n",
    "def scanner_final_com_tipo(setores):\n",
    "    print(\"Iniciando scanner final focado (filtrando por tipo 'stock' e 'fund')...\")\n",
    "    try:\n",
    "        url = \"https://brapi.dev/api/quote/list\"\n",
    "        lista_completa_brapi = requests.get(url).json().get('stocks', [])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro fatal ao buscar a lista da brapi: {e}\")\n",
    "        return {}\n",
    "\n",
    "    print(\"Mapeando ativos dos setores alvo...\")\n",
    "    tickers_para_analisar = {}\n",
    "    for stock in lista_completa_brapi:\n",
    "        setor_brapi = stock.get('sector')\n",
    "        tipo_ativo = stock.get('type')\n",
    "        if setor_brapi in setores and tipo_ativo in ['stock', 'fund']:\n",
    "            ticker = f\"{stock.get('stock')}.SA\"\n",
    "            tickers_para_analisar[ticker] = {\n",
    "                'setor': setor_brapi,\n",
    "                'logo': stock.get('logo'),\n",
    "                'tipo': tipo_ativo \n",
    "            }\n",
    "    \n",
    "    total = len(tickers_para_analisar)\n",
    "    print(f\"‚úÖ Mapeamento conclu√≠do. {total} ativos dos tipos 'stock' e 'fund' ser√£o analisados.\")\n",
    "\n",
    "    dados_finais = {}\n",
    "    print(\"\\nIniciando coleta detalhada de dados no yfinance...\")\n",
    "    for i, (ticker, brapi_data) in enumerate(tickers_para_analisar.items()):\n",
    "        try:\n",
    "            print(f\"Analisando [{i+1}/{total}]: {ticker}...\")\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            if info.get(\"country\") != \"Brazil\":\n",
    "                print(f\"  -> DESCARTADO: {ticker} n√£o √© do Brasil.\")\n",
    "                continue\n",
    "            \n",
    "            dados_finais[ticker] = {\n",
    "                \"Empresa\": info.get(\"longName\", \"N/A\"),\n",
    "                \"Setor (brapi)\": brapi_data['setor'],\n",
    "                \"Subsetor (yfinance)\": info.get(\"industry\", \"N/A\"),\n",
    "                \"Pa√≠s\": info.get(\"country\", \"N/A\"),\n",
    "                \"Tipo\": brapi_data['tipo'],\n",
    "                \"Market Cap\": info.get(\"marketCap\"),\n",
    "                \"Logo\": brapi_data['logo'],\n",
    "            }\n",
    "            print(f\"  -> ‚úÖ INCLU√çDO: {ticker}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> ERRO: Falha ao processar {ticker}. Erro: {e}\")\n",
    "            continue\n",
    "                \n",
    "    return dados_finais\n",
    "\n",
    "# --- EXECU√á√ÉO E APRESENTA√á√ÉO DOS RESULTADOS ---\n",
    "resultados = scanner_final_com_tipo(setores_alvo)\n",
    "\n",
    "if resultados:\n",
    "    print(\"\\n‚úÖ An√°lise finalizada.\")\n",
    "    df_resultado = pd.DataFrame.from_dict(resultados, orient=\"index\")\n",
    "    \n",
    "    df_resultado.reset_index(inplace=True)\n",
    "    df_resultado.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "    \n",
    "    if \"Market Cap\" in df_resultado.columns:\n",
    "         df_resultado[\"Market Cap Num\"] = pd.to_numeric(df_resultado[\"Market Cap\"], errors='coerce')\n",
    "         df_resultado[\"Market Cap\"] = df_resultado[\"Market Cap Num\"].apply(\n",
    "             lambda x: f\"R$ {x/1_000_000_000:.2f} Bi\" if pd.notna(x) and x > 0 else \"N/A\"\n",
    "         )\n",
    "\n",
    "    df_ordenado = df_resultado.sort_values(by=['Setor (brapi)', 'Market Cap Num'], ascending=[True, False])\n",
    "    \n",
    "    colunas_finais = ['Ticker', 'Empresa', 'Setor (brapi)', 'Subsetor (yfinance)', 'Pa√≠s', 'Tipo', 'Market Cap', 'Logo']\n",
    "    df_final = df_ordenado[colunas_finais]\n",
    "    \n",
    "    print(\"\\n--- Relat√≥rio Final (A√ß√µes e Fundos) ---\")\n",
    "    print(df_final.to_string(index=False))\n",
    "\n",
    "    # --- SALVANDO O ARQUIVO NO CAMINHO ESPEC√çFICO ---\n",
    "    try:\n",
    "        output_folder = r\"E:\\finance-manager\\data\"\n",
    "        output_filename = \"scanner_acoes_e_fundos_filtrado.csv\"\n",
    "        full_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        df_final.to_csv(full_path, index=False)\n",
    "        print(f\"\\n‚úÖ Resultados salvos com sucesso no caminho: {full_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro ao salvar o arquivo CSV: {e}\")\n",
    "else:\n",
    "    print(\"\\nNenhuma empresa foi encontrada para os crit√©rios especificados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1b6b5",
   "metadata": {},
   "source": [
    "## Extraindo dividendos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Carrega vari√°veis do .env\n",
    "load_dotenv()\n",
    "\n",
    "# Caminho do arquivo CSV com os tickers\n",
    "csv_path = os.getenv(\"FILTERED_COMPANIES_PATH\")\n",
    "\n",
    "# L√™ o CSV e extrai os tickers\n",
    "df = pd.read_csv(csv_path)\n",
    "tickers = df['Ticker'].dropna().unique().tolist()\n",
    "\n",
    "# Define o per√≠odo de 7 anos\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=7*365)\n",
    "\n",
    "todos_dividendos = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        acao = yf.Ticker(ticker)\n",
    "        dividendos = acao.dividends\n",
    "\n",
    "        # Remove timezone do √≠ndice\n",
    "        dividendos.index = dividendos.index.tz_localize(None)\n",
    "\n",
    "        # Filtra dividendos dos √∫ltimos 7 anos\n",
    "        dividendos = dividendos[dividendos.index >= start_date]\n",
    "\n",
    "        if not dividendos.empty:\n",
    "            df_div = dividendos.reset_index()\n",
    "            df_div.columns = ['Data', 'Valor']\n",
    "            df_div['Ticker'] = ticker.replace('.SA', '')\n",
    "            todos_dividendos.append(df_div)\n",
    "\n",
    "            print(f\"‚úÖ Dividendos coletados para {ticker}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Sem dividendos recentes para {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao processar {ticker}: {e}\")\n",
    "\n",
    "# Junta tudo em um √∫nico DataFrame\n",
    "df_final = pd.concat(todos_dividendos, ignore_index=True)\n",
    "\n",
    "# Salva em um √∫nico CSV\n",
    "df_final.to_csv(\"../data/todos_dividendos.csv\", index=False)\n",
    "\n",
    "print(\"üèÅ Finalizado! Dividendos salvos em todos_dividendos.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd63b78",
   "metadata": {},
   "source": [
    "### Dividendo por ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c59dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ler o arquivo CSV\n",
    "df = pd.read_csv('../data/todos_dividendos.csv')\n",
    "\n",
    "# Converter a coluna 'Data' para datetime e extrair o ano\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "df['ano'] = df['Data'].dt.year\n",
    "\n",
    "# Renomear colunas para min√∫sculas\n",
    "df = df.rename(columns={'Ticker': 'ticket', 'Valor': 'dividendo', 'Data': 'data'})\n",
    "\n",
    "# Somar os dividendos por ano e ticket\n",
    "soma_por_ano_ticket = df.groupby(['ano', 'ticket'])['dividendo'].sum().reset_index()\n",
    "\n",
    "# Salvar o resultado em um CSV\n",
    "soma_por_ano_ticket.to_csv('../data/dividendos_ano.csv', index=False)\n",
    "print(\"Arquivo 'dividendos_ano.csv' gerado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ed02a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ano  ticket  dividendo\n",
      "0  2018   AFLT3   0.104383\n",
      "1  2018   AGRO3   0.762051\n",
      "2  2018  ALUP11   0.160019\n",
      "3  2018   ALUP3   0.053340\n",
      "4  2018   ALUP4   0.053340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "div_ano = pd.read_csv('../data/dividendos_ano.csv')\n",
    "print(div_ano.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47693105",
   "metadata": {},
   "source": [
    "### Dividendos por ano resumido (DY5 e DY12M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c9680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'dividendos_ano_resumo.csv' gerado com sucesso!\n",
      "   ticket  valor_5anos  valor_12m\n",
      "0   ABCB4     6.902438   1.086000\n",
      "1   AFLT3     1.894183   0.017041\n",
      "2   AGRO3    12.644483   0.000000\n",
      "3   ALOS3     3.347996   0.691226\n",
      "4  ALUP11     5.310194   0.450000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os dividendos por ano e ticket\n",
    "df = pd.read_csv('../data/dividendos_ano.csv')\n",
    "\n",
    "# Descobrir o √∫ltimo ano dispon√≠vel\n",
    "ultimo_ano = df['ano'].max()\n",
    "\n",
    "# Dividendos dos √∫ltimos 5 anos\n",
    "div_5anos = df[df['ano'] >= ultimo_ano - 4]\n",
    "soma_5anos = div_5anos.groupby('ticket')['dividendo'].sum().reset_index()\n",
    "soma_5anos = soma_5anos.rename(columns={'dividendo': 'valor_5anos'})\n",
    "\n",
    "# Dividendos dos √∫ltimos 12 meses\n",
    "div_12m = df[df['ano'] == ultimo_ano]\n",
    "soma_12m = div_12m[['ticket', 'dividendo']].rename(columns={'dividendo': 'valor_12m'})\n",
    "\n",
    "# Juntar os dois\n",
    "resumo = pd.merge(soma_5anos, soma_12m, on='ticket', how='outer').fillna(0)\n",
    "\n",
    "# Reorganizar colunas\n",
    "resumo = resumo[['ticket', 'valor_5anos', 'valor_12m']]\n",
    "\n",
    "# Salvar resultado\n",
    "resumo.to_csv('../data/dividendos_ano_resumo.csv', index=False)\n",
    "print(\"Arquivo 'dividendos_ano_resumo.csv' gerado com sucesso!\")\n",
    "print(resumo.head())\n",
    "print(resumo.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f7389",
   "metadata": {},
   "source": [
    "## Extraindo valores das a√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585cff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b65de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7017d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rever o codigo abaixo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad630061",
   "metadata": {},
   "source": [
    "## Script de Transforma√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform.py (Vers√£o com C√°lculo de DY Padronizado)\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def classify_stock_profile(price: float, market_cap: float) -> str:\n",
    "    \"\"\"\n",
    "    Classifica a a√ß√£o com base no Market Cap e Pre√ßo.\n",
    "    \"\"\"\n",
    "    if price is not None and price < 1.0:\n",
    "        return \"Penny Stock\"\n",
    "    if market_cap is None or market_cap == 0:\n",
    "        return \"N/A\"\n",
    "    if market_cap > 50_000_000_000:\n",
    "        return \"Blue Chip\"\n",
    "    if market_cap > 10_000_000_000:\n",
    "        return \"Mid Cap\"\n",
    "    if market_cap > 2_000_000_000:\n",
    "        return \"Small Cap\"\n",
    "    return \"Micro Cap\"\n",
    "\n",
    "def get_market_sentiment_and_details(ticker_obj: yf.Ticker) -> dict:\n",
    "    \"\"\"\n",
    "    Usa 'recommendations_summary' para maior robustez.\n",
    "    \"\"\"\n",
    "    sentiment_data = {\n",
    "        'Sentimento Gauge': 50.0, 'Strong Buy': 0, 'Buy': 0,\n",
    "        'Hold': 0, 'Sell': 0, 'Strong Sell': 0\n",
    "    }\n",
    "    try:\n",
    "        summary = ticker_obj.recommendations_summary\n",
    "        if summary is None or summary.empty:\n",
    "            return sentiment_data\n",
    "        rec_counts = summary.iloc[-1]\n",
    "        strong_buy = int(rec_counts.get('strongBuy', 0))\n",
    "        buy = int(rec_counts.get('buy', 0))\n",
    "        hold = int(rec_counts.get('hold', 0))\n",
    "        sell = int(rec_counts.get('sell', 0))\n",
    "        strong_sell = int(rec_counts.get('strongSell', 0))\n",
    "        sentiment_data.update({\n",
    "            'Strong Buy': strong_buy, 'Buy': buy, 'Hold': hold,\n",
    "            'Sell': sell, 'Strong Sell': strong_sell\n",
    "        })\n",
    "        weighted_score = (strong_buy * 2) + (buy * 1) + (hold * 0) + (sell * -1) + (strong_sell * -2)\n",
    "        total_recommendations = strong_buy + buy + hold + sell + strong_sell\n",
    "        if total_recommendations == 0:\n",
    "            return sentiment_data\n",
    "        avg_score = weighted_score / total_recommendations\n",
    "        normalized_sentiment = ((avg_score + 2) / 4) * 100\n",
    "        sentiment_data['Sentimento Gauge'] = normalized_sentiment\n",
    "        return sentiment_data\n",
    "    except Exception as e:\n",
    "        print(f\" (Aviso: Falha ao buscar sentimento - {e}) \", end=\"\")\n",
    "        return sentiment_data\n",
    "\n",
    "def fetch_stock_data(ticker: str, info_original: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Busca e processa os dados de um √∫nico ticker, com l√≥gica de fallback para Market Cap e DY 5 anos.\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    info = stock.info\n",
    "    history = stock.history(period=\"5y\")\n",
    "\n",
    "    market_cap = info.get('marketCap')\n",
    "    current_price = info.get(\"currentPrice\", 0.0)\n",
    "    if not market_cap or market_cap == 0:\n",
    "        shares_outstanding = info.get('sharesOutstanding', 0)\n",
    "        if shares_outstanding > 0 and current_price > 0:\n",
    "            market_cap = shares_outstanding * current_price\n",
    "    if not market_cap or market_cap == 0:\n",
    "        market_cap = info_original.get('Market Cap', 0)\n",
    "\n",
    "    # --- C√°lculos de Indicadores ---\n",
    "    # Dividend Yield 12 meses (j√° em percentual, apenas valida)\n",
    "    dy_12m = info.get(\"trailingAnnualDividendYield\", 0.0) * 100 if info.get(\"trailingAnnualDividendYield\") is not None else 0.0\n",
    "    if dy_12m > 50 or dy_12m < 0:\n",
    "        dy_12m = 0.0  # Prote√ß√£o contra valores absurdos\n",
    "\n",
    "    # Dividend Yield 5 anos (evitar multiplica√ß√£o por 100 e adicionar fallback)\n",
    "    dy_5y = info.get(\"fiveYearAvgDividendYield\", 0.0) if info.get(\"fiveYearAvgDividendYield\") is not None else 0.0\n",
    "    # Valida√ß√£o: valores fora de 0-50% s√£o considerados inv√°lidos\n",
    "    if dy_5y > 50 or dy_5y < 0:\n",
    "        print(f\" (Aviso: DY 5 anos de {ticker} ({dy_5y:.2f}%) inv√°lido, calculando manualmente...) \", end=\"\")\n",
    "        dy_5y = 0.0\n",
    "        try:\n",
    "            dividends = stock.dividends\n",
    "            if not dividends.empty:\n",
    "                # Soma os dividendos dos √∫ltimos 5 anos\n",
    "                dividends_5y = dividends[dividends.index >= (datetime.now() - pd.Timedelta(days=5*365))]\n",
    "                total_dividends = dividends_5y.sum()\n",
    "                # Calcula pre√ßo m√©dio dos √∫ltimos 5 anos\n",
    "                avg_price = history['Close'].mean() if not history.empty else current_price\n",
    "                if avg_price > 0:\n",
    "                    dy_5y = (total_dividends / 5) / avg_price * 100  # M√©dia anual de dividendos / pre√ßo m√©dio\n",
    "        except Exception as e:\n",
    "            print(f\" (Aviso: Falha ao calcular DY 5 anos manualmente para {ticker} - {e}) \", end=\"\")\n",
    "\n",
    "    growth_price = 0.0\n",
    "    if not history.empty and len(history['Close']) > 1 and history['Close'].iloc[0] > 0:\n",
    "        growth_price = ((history['Close'].iloc[-1] / history['Close'].iloc[0]) - 1) * 100\n",
    "    payout_ratio = info.get(\"payoutRatio\", 0.0) * 100 if info.get(\"payoutRatio\") is not None else 0.0\n",
    "    sentiment_info = get_market_sentiment_and_details(stock)\n",
    "\n",
    "    dados = {\n",
    "        \"Empresa\": info_original.get('Empresa', 'N/A'),\n",
    "        \"Setor (brapi)\": info_original.get('Setor (brapi)', 'N/A'),\n",
    "        \"Tipo\": info_original.get('Tipo', 'N/A'),\n",
    "        \"Market Cap\": market_cap,\n",
    "        \"Logo\": info_original.get('Logo', 'N/A'),\n",
    "        \"Pre√ßo Atual\": current_price,\n",
    "        \"P/L\": info.get(\"trailingPE\"),\n",
    "        \"P/VP\": info.get(\"priceToBook\"),\n",
    "        \"DY (Taxa 12m, %)\": dy_12m,\n",
    "        \"DY 5 Anos M√©dia (%)\": dy_5y,\n",
    "        \"√öltimo Dividendo\": info.get(\"lastDividendValue\"),\n",
    "        \"Data √ölt. Div.\": pd.to_datetime(info.get(\"lastDividendDate\"), unit='s', errors='coerce'),\n",
    "        \"Data Ex-Div.\": pd.to_datetime(info.get(\"exDividendDate\"), unit='s', errors='coerce'),\n",
    "        \"Payout Ratio (%)\": payout_ratio,\n",
    "        \"Crescimento Pre√ßo (%)\": growth_price,\n",
    "        \"ROE (%)\": info.get(\"returnOnEquity\", 0.0) * 100 if info.get(\"returnOnEquity\") is not None else 0.0,\n",
    "        \"D√≠vida Total\": info.get('totalDebt'),\n",
    "        \"EBITDA\": info.get('ebitda'),\n",
    "        \"Perfil da A√ß√£o\": classify_stock_profile(current_price, market_cap)\n",
    "    }\n",
    "    dados.update(sentiment_info)\n",
    "    if dados.get(\"EBITDA\") and dados[\"EBITDA\"] != 0 and dados.get(\"D√≠vida Total\"):\n",
    "        dados[\"D√≠vida/EBITDA\"] = dados[\"D√≠vida Total\"] / dados[\"EBITDA\"]\n",
    "    else:\n",
    "        dados[\"D√≠vida/EBITDA\"] = None\n",
    "    return dados\n",
    "\n",
    "def main():\n",
    "    arquivo_input = r\"E:\\Github\\Unicamp\\finance-manager\\data\\scanner_acoes_e_fundos_filtrado.csv\"\n",
    "    output_path = r\"E:\\Github\\Unicamp\\finance-manager\\data\\relatorio_analise_b3.csv\"\n",
    "    try:\n",
    "        df_input = pd.read_csv(arquivo_input)\n",
    "        tickers_para_analisar = df_input['Ticker'].tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå ERRO CR√çTICO: Arquivo de entrada '{arquivo_input}' n√£o encontrado.\")\n",
    "        return\n",
    "    dados_detalhados = {}\n",
    "    erros = []\n",
    "    print(\"\\nIniciando coleta de dados via yfinance...\")\n",
    "    for ticker in tickers_para_analisar:\n",
    "        print(f\"Processando: {ticker}...\", end=\"\")\n",
    "        try:\n",
    "            info_original = df_input[df_input['Ticker'] == ticker].iloc[0]\n",
    "            dados_detalhados[ticker] = fetch_stock_data(ticker, info_original)\n",
    "            print(\" ‚úÖ\")\n",
    "        except Exception as e:\n",
    "            erros.append(ticker)\n",
    "            print(f\" ‚ùå (Erro: {e})\")\n",
    "    if not dados_detalhados:\n",
    "        print(\"\\n‚ùå NENHUM DADO FOI COLETADO COM SUCESSO. O arquivo CSV n√£o ser√° gerado.\")\n",
    "        return\n",
    "    df_resultado = pd.DataFrame.from_dict(dados_detalhados, orient=\"index\")\n",
    "    df_resultado.fillna(0, inplace=True)\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        df_resultado.to_csv(output_path)\n",
    "        print(f\"\\n‚úÖ SUCESSO! Relat√≥rio salvo com sucesso em: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRO INESPERADO AO SALVAR O ARQUIVO: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f857af",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # arquivo_input = r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\scanner_acoes_e_fundos_filtrado.csv\"\n",
    "    # output_path = r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\relatorio_analise_b3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py:\n",
    "\n",
    "# df = load_data(r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\relatorio_analise_b3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_dados = pd.read_excel(r'E:\\Github\\finance-manager\\datasets\\relatorio_completo_b3.xlsx')\n",
    "\n",
    "# print(df_dados.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
