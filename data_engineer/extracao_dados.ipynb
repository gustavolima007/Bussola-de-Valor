{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d56c0ba",
   "metadata": {},
   "source": [
    "# Extraindo empresas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e53cf",
   "metadata": {},
   "source": [
    "## Extraindo todas empresas do Brasil da categoria BESST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- PASSO 1: CONFIGURAÇÃO DOS SETORES-ALVO ---\n",
    "setores_alvo = [\n",
    "    \"Finance\",\n",
    "    \"Utilities\",\n",
    "    \"Communications\",\n",
    "    \"Industrial Services\"\n",
    "]\n",
    "\n",
    "# --- FUNÇÃO PRINCIPAL COM A LÓGICA FINAL ---\n",
    "def scanner_final_com_tipo(setores):\n",
    "    print(\"Iniciando scanner final focado (filtrando por tipo 'stock' e 'fund')...\")\n",
    "    try:\n",
    "        url = \"https://brapi.dev/api/quote/list\"\n",
    "        lista_completa_brapi = requests.get(url).json().get('stocks', [])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro fatal ao buscar a lista da brapi: {e}\")\n",
    "        return {}\n",
    "\n",
    "    print(\"Mapeando ativos dos setores alvo...\")\n",
    "    tickers_para_analisar = {}\n",
    "    for stock in lista_completa_brapi:\n",
    "        setor_brapi = stock.get('sector')\n",
    "        tipo_ativo = stock.get('type')\n",
    "        if setor_brapi in setores and tipo_ativo in ['stock', 'fund']:\n",
    "            ticker = f\"{stock.get('stock')}.SA\"\n",
    "            tickers_para_analisar[ticker] = {\n",
    "                'setor': setor_brapi,\n",
    "                'logo': stock.get('logo'),\n",
    "                'tipo': tipo_ativo \n",
    "            }\n",
    "    \n",
    "    total = len(tickers_para_analisar)\n",
    "    print(f\"✅ Mapeamento concluído. {total} ativos dos tipos 'stock' e 'fund' serão analisados.\")\n",
    "\n",
    "    dados_finais = {}\n",
    "    print(\"\\nIniciando coleta detalhada de dados no yfinance...\")\n",
    "    for i, (ticker, brapi_data) in enumerate(tickers_para_analisar.items()):\n",
    "        try:\n",
    "            print(f\"Analisando [{i+1}/{total}]: {ticker}...\")\n",
    "            stock = yf.Ticker(ticker)\n",
    "            info = stock.info\n",
    "            \n",
    "            if info.get(\"country\") != \"Brazil\":\n",
    "                print(f\"  -> DESCARTADO: {ticker} não é do Brasil.\")\n",
    "                continue\n",
    "            \n",
    "            dados_finais[ticker] = {\n",
    "                \"Empresa\": info.get(\"longName\", \"N/A\"),\n",
    "                \"Setor (brapi)\": brapi_data['setor'],\n",
    "                \"Subsetor (yfinance)\": info.get(\"industry\", \"N/A\"),\n",
    "                \"País\": info.get(\"country\", \"N/A\"),\n",
    "                \"Tipo\": brapi_data['tipo'],\n",
    "                \"Market Cap\": info.get(\"marketCap\"),\n",
    "                \"Logo\": brapi_data['logo'],\n",
    "            }\n",
    "            print(f\"  -> ✅ INCLUÍDO: {ticker}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  -> ERRO: Falha ao processar {ticker}. Erro: {e}\")\n",
    "            continue\n",
    "                \n",
    "    return dados_finais\n",
    "\n",
    "# --- EXECUÇÃO E APRESENTAÇÃO DOS RESULTADOS ---\n",
    "resultados = scanner_final_com_tipo(setores_alvo)\n",
    "\n",
    "if resultados:\n",
    "    print(\"\\n✅ Análise finalizada.\")\n",
    "    df_resultado = pd.DataFrame.from_dict(resultados, orient=\"index\")\n",
    "    \n",
    "    df_resultado.reset_index(inplace=True)\n",
    "    df_resultado.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "    \n",
    "    if \"Market Cap\" in df_resultado.columns:\n",
    "         df_resultado[\"Market Cap Num\"] = pd.to_numeric(df_resultado[\"Market Cap\"], errors='coerce')\n",
    "         df_resultado[\"Market Cap\"] = df_resultado[\"Market Cap Num\"].apply(\n",
    "             lambda x: f\"R$ {x/1_000_000_000:.2f} Bi\" if pd.notna(x) and x > 0 else \"N/A\"\n",
    "         )\n",
    "\n",
    "    df_ordenado = df_resultado.sort_values(by=['Setor (brapi)', 'Market Cap Num'], ascending=[True, False])\n",
    "    \n",
    "    colunas_finais = ['Ticker', 'Empresa', 'Setor (brapi)', 'Subsetor (yfinance)', 'País', 'Tipo', 'Market Cap', 'Logo']\n",
    "    df_final = df_ordenado[colunas_finais]\n",
    "    \n",
    "    print(\"\\n--- Relatório Final (Ações e Fundos) ---\")\n",
    "    print(df_final.to_string(index=False))\n",
    "\n",
    "    # --- SALVANDO O ARQUIVO NO CAMINHO ESPECÍFICO ---\n",
    "    try:\n",
    "        output_folder = r\"E:\\finance-manager\\data\"\n",
    "        output_filename = \"scanner_acoes_e_fundos_filtrado.csv\"\n",
    "        full_path = os.path.join(output_folder, output_filename)\n",
    "        \n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        df_final.to_csv(full_path, index=False)\n",
    "        print(f\"\\n✅ Resultados salvos com sucesso no caminho: {full_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Erro ao salvar o arquivo CSV: {e}\")\n",
    "else:\n",
    "    print(\"\\nNenhuma empresa foi encontrada para os critérios especificados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_dados2 = pd.read_excel(r'E:\\Github\\finance-manager\\datasets\\scanner_acoes_filtrado.xlsx')\n",
    "\n",
    "# print(df_dados2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad630061",
   "metadata": {},
   "source": [
    "# Transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ee0373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando coleta de dados via yfinance...\n",
      "Processando: VIVT3.SA... ✅\n",
      "Processando: TIMS3.SA... ✅\n",
      "Processando: FIQE3.SA... ✅\n",
      "Processando: BRST3.SA... ✅\n",
      "Processando: DESK3.SA... ✅\n",
      "Processando: TELB4.SA... ✅\n",
      "Processando: TELB3.SA... ✅\n",
      "Processando: OIBR3.SA... ✅\n",
      "Processando: OIBR4.SA... ✅\n",
      "Processando: ITUB3.SA... ✅\n",
      "Processando: ITUB4.SA... ✅\n",
      "Processando: BPAC3.SA... ✅\n",
      "Processando: BPAC5.SA... ✅\n",
      "Processando: BBDC3.SA... ✅\n",
      "Processando: BBDC4.SA... ✅\n",
      "Processando: BPAC11.SA... ✅\n",
      "Processando: SANB11.SA... ✅\n",
      "Processando: BBAS3.SA... ✅\n",
      "Processando: ITSA4.SA... ✅\n",
      "Processando: ITSA3.SA... ✅\n",
      "Processando: SANB3.SA... ✅\n",
      "Processando: SANB4.SA... ✅\n",
      "Processando: B3SA3.SA... ✅\n",
      "Processando: BBSE3.SA... ✅\n",
      "Processando: CXSE3.SA... ✅\n",
      "Processando: RENT3.SA... ✅\n",
      "Processando: PSSA3.SA... ✅\n",
      "Processando: MULT3.SA... ✅\n",
      "Processando: ALOS3.SA... ✅\n",
      "Processando: BPAN4.SA... ✅\n",
      "Processando: CYRE3.SA... ✅\n",
      "Processando: BNBR3.SA... ✅\n",
      "Processando: CURY3.SA... ✅\n",
      "Processando: DIRR3.SA... ✅\n",
      "Processando: IGTI3.SA... ✅\n",
      "Processando: BRAP3.SA... ✅\n",
      "Processando: BRAP4.SA... ✅\n",
      "Processando: ABCB4.SA... ✅\n",
      "Processando: BRSR6.SA... ✅\n",
      "Processando: BRSR3.SA... ✅\n",
      "Processando: VAMO3.SA... ✅\n",
      "Processando: BAZA3.SA... ✅\n",
      "Processando: BSLI3.SA... ✅\n",
      "Processando: BSLI4.SA... ✅\n",
      "Processando: BMEB4.SA... ✅\n",
      "Processando: IRBR3.SA... ✅\n",
      "Processando: JHSF3.SA... ✅\n",
      "Processando: PLPL3.SA... ✅\n",
      "Processando: EZTC3.SA... ✅\n",
      "Processando: TEND3.SA... ✅\n",
      "Processando: BEES4.SA... ✅\n",
      "Processando: BEES3.SA... ✅\n",
      "Processando: MILS3.SA... ✅\n",
      "Processando: LAVV3.SA... ✅\n",
      "Processando: MOVI3.SA... ✅\n",
      "Processando: BMGB4.SA... ✅\n",
      "Processando: AGRO3.SA... ✅\n",
      "Processando: MDNE3.SA... ✅\n",
      "Processando: EVEN3.SA... ✅\n",
      "Processando: PINE3.SA... ✅\n",
      "Processando: PINE4.SA... ✅\n",
      "Processando: WIZC3.SA... ✅\n",
      "Processando: ARML3.SA... ✅\n",
      "Processando: SCAR3.SA... ✅\n",
      "Processando: SYNE3.SA... ✅\n",
      "Processando: LAND3.SA... ✅\n",
      "Processando: PEAB4.SA... ✅\n",
      "Processando: BGIP4.SA... ✅\n",
      "Processando: MTRE3.SA... ✅\n",
      "Processando: RPAD3.SA... ✅\n",
      "Processando: SNCI11.SA... ✅\n",
      "Processando: HBRE3.SA... ✅\n",
      "Processando: AVLL3.SA... ✅\n",
      "Processando: GFSA3.SA... ✅\n",
      "Processando: IRIM11.SA... ✅\n",
      "Processando: TCSA3.SA... ✅\n",
      "Processando: RDNI3.SA... ✅\n",
      "Processando: BMIN4.SA... ✅\n",
      "Processando: PPLA11.SA... ✅\n",
      "Processando: NEXP3.SA... ✅\n",
      "Processando: PDGR3.SA... ✅\n",
      "Processando: RENV11.SA... ✅\n",
      "Processando: EGYR11.SA... ✅\n",
      "Processando: IGTI11.SA... ✅\n",
      "Processando: BRBI11.SA... ✅\n",
      "Processando: RBIF11.SA... ✅\n",
      "Processando: TAEE11.SA... ✅\n",
      "Processando: TAEE3.SA... ✅\n",
      "Processando: TAEE4.SA... ✅\n",
      "Processando: LOGG3.SA... ✅\n",
      "Processando: PRNR3.SA... ✅\n",
      "Processando: MELK3.SA... ✅\n",
      "Processando: AZEV3.SA... ✅\n",
      "Processando: AZEV4.SA... ✅\n",
      "Processando: AZTE3.SA... ✅\n",
      "Processando: INEP3.SA... ✅\n",
      "Processando: INEP4.SA... ✅\n",
      "Processando: OSXB3.SA... ✅\n",
      "Processando: ELET3.SA... ✅\n",
      "Processando: ELET6.SA... ✅\n",
      "Processando: SBSP3.SA... ✅\n",
      "Processando: CPFE3.SA... ✅\n",
      "Processando: EQTL3.SA... ✅\n",
      "Processando: EGIE3.SA... ✅\n",
      "Processando: CPLE3.SA... ✅\n",
      "Processando: CPLE6.SA... ✅\n",
      "Processando: CMIG4.SA... ✅\n",
      "Processando: CMIG3.SA... ✅\n",
      "Processando: NEOE3.SA... ✅\n",
      "Processando: ENEV3.SA... ✅\n",
      "Processando: ENGI4.SA... ✅\n",
      "Processando: ENGI3.SA... ✅\n",
      "Processando: ENGI11.SA... ✅\n",
      "Processando: ISAE4.SA... ✅\n",
      "Processando: ENMT3.SA... ✅\n",
      "Processando: ISAE3.SA... ✅\n",
      "Processando: CGAS3.SA... ✅\n",
      "Processando: CGAS5.SA... ✅\n",
      "Processando: ALUP11.SA... ✅\n",
      "Processando: REDE3.SA... ✅\n",
      "Processando: CSAN3.SA... ✅\n",
      "Processando: EQPA3.SA... ✅\n",
      "Processando: SAPR3.SA... ✅\n",
      "Processando: SAPR11.SA... ✅\n",
      "Processando: SAPR4.SA... ✅\n",
      "Processando: AURE3.SA... ✅\n",
      "Processando: CSMG3.SA... ✅\n",
      "Processando: ALUP4.SA... ✅\n",
      "Processando: ALUP3.SA... ✅\n",
      "Processando: EKTR4.SA... ✅\n",
      "Processando: SRNA3.SA... ✅\n",
      "Processando: ORVR3.SA... ✅\n",
      "Processando: EQMA3B.SA... ✅\n",
      "Processando: CLSC4.SA... ✅\n",
      "Processando: GEPA4.SA... ✅\n",
      "Processando: LIGT3.SA... ✅\n",
      "Processando: COCE5.SA... ✅\n",
      "Processando: CEBR3.SA... ✅\n",
      "Processando: CEBR5.SA... ✅\n",
      "Processando: CEBR6.SA... ✅\n",
      "Processando: EMAE4.SA... ✅\n",
      "Processando: RNEW11.SA... ✅\n",
      "Processando: AFLT3.SA... ✅\n",
      "Processando: RNEW4.SA... ✅\n",
      "Processando: RNEW3.SA... ✅\n",
      "\n",
      "✅ SUCESSO! Relatório salvo com sucesso em: C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\relatorio_analise_b3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\01701805\\AppData\\Local\\Temp\\52\\ipykernel_63540\\3818950204.py:158: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  df_resultado.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# transform.py (Versão com Cálculo de DY Padronizado)\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def classify_stock_profile(price: float, market_cap: float) -> str:\n",
    "    \"\"\"\n",
    "    Classifica a ação com base no Market Cap e Preço.\n",
    "    \"\"\"\n",
    "    if price is not None and price < 1.0:\n",
    "        return \"Penny Stock\"\n",
    "    if market_cap is None or market_cap == 0:\n",
    "        return \"N/A\"\n",
    "    if market_cap > 50_000_000_000:\n",
    "        return \"Blue Chip\"\n",
    "    if market_cap > 10_000_000_000:\n",
    "        return \"Mid Cap\"\n",
    "    if market_cap > 2_000_000_000:\n",
    "        return \"Small Cap\"\n",
    "    return \"Micro Cap\"\n",
    "\n",
    "def get_market_sentiment_and_details(ticker_obj: yf.Ticker) -> dict:\n",
    "    \"\"\"\n",
    "    Usa 'recommendations_summary' para maior robustez.\n",
    "    \"\"\"\n",
    "    sentiment_data = {\n",
    "        'Sentimento Gauge': 50.0, 'Strong Buy': 0, 'Buy': 0,\n",
    "        'Hold': 0, 'Sell': 0, 'Strong Sell': 0\n",
    "    }\n",
    "    try:\n",
    "        summary = ticker_obj.recommendations_summary\n",
    "        if summary is None or summary.empty:\n",
    "            return sentiment_data\n",
    "        rec_counts = summary.iloc[-1]\n",
    "        strong_buy = int(rec_counts.get('strongBuy', 0))\n",
    "        buy = int(rec_counts.get('buy', 0))\n",
    "        hold = int(rec_counts.get('hold', 0))\n",
    "        sell = int(rec_counts.get('sell', 0))\n",
    "        strong_sell = int(rec_counts.get('strongSell', 0))\n",
    "        sentiment_data.update({\n",
    "            'Strong Buy': strong_buy, 'Buy': buy, 'Hold': hold,\n",
    "            'Sell': sell, 'Strong Sell': strong_sell\n",
    "        })\n",
    "        weighted_score = (strong_buy * 2) + (buy * 1) + (hold * 0) + (sell * -1) + (strong_sell * -2)\n",
    "        total_recommendations = strong_buy + buy + hold + sell + strong_sell\n",
    "        if total_recommendations == 0:\n",
    "            return sentiment_data\n",
    "        avg_score = weighted_score / total_recommendations\n",
    "        normalized_sentiment = ((avg_score + 2) / 4) * 100\n",
    "        sentiment_data['Sentimento Gauge'] = normalized_sentiment\n",
    "        return sentiment_data\n",
    "    except Exception as e:\n",
    "        print(f\" (Aviso: Falha ao buscar sentimento - {e}) \", end=\"\")\n",
    "        return sentiment_data\n",
    "\n",
    "def fetch_stock_data(ticker: str, info_original: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Busca e processa os dados de um único ticker, com lógica de fallback para Market Cap e DY 5 anos.\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    info = stock.info\n",
    "    history = stock.history(period=\"5y\")\n",
    "\n",
    "    market_cap = info.get('marketCap')\n",
    "    current_price = info.get(\"currentPrice\", 0.0)\n",
    "    if not market_cap or market_cap == 0:\n",
    "        shares_outstanding = info.get('sharesOutstanding', 0)\n",
    "        if shares_outstanding > 0 and current_price > 0:\n",
    "            market_cap = shares_outstanding * current_price\n",
    "    if not market_cap or market_cap == 0:\n",
    "        market_cap = info_original.get('Market Cap', 0)\n",
    "\n",
    "    # --- Cálculos de Indicadores ---\n",
    "    # Dividend Yield 12 meses (já em percentual, apenas valida)\n",
    "    dy_12m = info.get(\"trailingAnnualDividendYield\", 0.0) * 100 if info.get(\"trailingAnnualDividendYield\") is not None else 0.0\n",
    "    if dy_12m > 50 or dy_12m < 0:\n",
    "        dy_12m = 0.0  # Proteção contra valores absurdos\n",
    "\n",
    "    # Dividend Yield 5 anos (evitar multiplicação por 100 e adicionar fallback)\n",
    "    dy_5y = info.get(\"fiveYearAvgDividendYield\", 0.0) if info.get(\"fiveYearAvgDividendYield\") is not None else 0.0\n",
    "    # Validação: valores fora de 0-50% são considerados inválidos\n",
    "    if dy_5y > 50 or dy_5y < 0:\n",
    "        print(f\" (Aviso: DY 5 anos de {ticker} ({dy_5y:.2f}%) inválido, calculando manualmente...) \", end=\"\")\n",
    "        dy_5y = 0.0\n",
    "        try:\n",
    "            dividends = stock.dividends\n",
    "            if not dividends.empty:\n",
    "                # Soma os dividendos dos últimos 5 anos\n",
    "                dividends_5y = dividends[dividends.index >= (datetime.now() - pd.Timedelta(days=5*365))]\n",
    "                total_dividends = dividends_5y.sum()\n",
    "                # Calcula preço médio dos últimos 5 anos\n",
    "                avg_price = history['Close'].mean() if not history.empty else current_price\n",
    "                if avg_price > 0:\n",
    "                    dy_5y = (total_dividends / 5) / avg_price * 100  # Média anual de dividendos / preço médio\n",
    "        except Exception as e:\n",
    "            print(f\" (Aviso: Falha ao calcular DY 5 anos manualmente para {ticker} - {e}) \", end=\"\")\n",
    "\n",
    "    growth_price = 0.0\n",
    "    if not history.empty and len(history['Close']) > 1 and history['Close'].iloc[0] > 0:\n",
    "        growth_price = ((history['Close'].iloc[-1] / history['Close'].iloc[0]) - 1) * 100\n",
    "    payout_ratio = info.get(\"payoutRatio\", 0.0) * 100 if info.get(\"payoutRatio\") is not None else 0.0\n",
    "    sentiment_info = get_market_sentiment_and_details(stock)\n",
    "\n",
    "    dados = {\n",
    "        \"Empresa\": info_original.get('Empresa', 'N/A'),\n",
    "        \"Setor (brapi)\": info_original.get('Setor (brapi)', 'N/A'),\n",
    "        \"Tipo\": info_original.get('Tipo', 'N/A'),\n",
    "        \"Market Cap\": market_cap,\n",
    "        \"Logo\": info_original.get('Logo', 'N/A'),\n",
    "        \"Preço Atual\": current_price,\n",
    "        \"P/L\": info.get(\"trailingPE\"),\n",
    "        \"P/VP\": info.get(\"priceToBook\"),\n",
    "        \"DY (Taxa 12m, %)\": dy_12m,\n",
    "        \"DY 5 Anos Média (%)\": dy_5y,\n",
    "        \"Último Dividendo\": info.get(\"lastDividendValue\"),\n",
    "        \"Data Últ. Div.\": pd.to_datetime(info.get(\"lastDividendDate\"), unit='s', errors='coerce'),\n",
    "        \"Data Ex-Div.\": pd.to_datetime(info.get(\"exDividendDate\"), unit='s', errors='coerce'),\n",
    "        \"Payout Ratio (%)\": payout_ratio,\n",
    "        \"Crescimento Preço (%)\": growth_price,\n",
    "        \"ROE (%)\": info.get(\"returnOnEquity\", 0.0) * 100 if info.get(\"returnOnEquity\") is not None else 0.0,\n",
    "        \"Dívida Total\": info.get('totalDebt'),\n",
    "        \"EBITDA\": info.get('ebitda'),\n",
    "        \"Perfil da Ação\": classify_stock_profile(current_price, market_cap)\n",
    "    }\n",
    "    dados.update(sentiment_info)\n",
    "    if dados.get(\"EBITDA\") and dados[\"EBITDA\"] != 0 and dados.get(\"Dívida Total\"):\n",
    "        dados[\"Dívida/EBITDA\"] = dados[\"Dívida Total\"] / dados[\"EBITDA\"]\n",
    "    else:\n",
    "        dados[\"Dívida/EBITDA\"] = None\n",
    "    return dados\n",
    "\n",
    "def main():\n",
    "    arquivo_input = r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\scanner_acoes_e_fundos_filtrado.csv\"\n",
    "    output_path = r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\relatorio_analise_b3.csv\"\n",
    "    try:\n",
    "        df_input = pd.read_csv(arquivo_input)\n",
    "        tickers_para_analisar = df_input['Ticker'].tolist()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ ERRO CRÍTICO: Arquivo de entrada '{arquivo_input}' não encontrado.\")\n",
    "        return\n",
    "    dados_detalhados = {}\n",
    "    erros = []\n",
    "    print(\"\\nIniciando coleta de dados via yfinance...\")\n",
    "    for ticker in tickers_para_analisar:\n",
    "        print(f\"Processando: {ticker}...\", end=\"\")\n",
    "        try:\n",
    "            info_original = df_input[df_input['Ticker'] == ticker].iloc[0]\n",
    "            dados_detalhados[ticker] = fetch_stock_data(ticker, info_original)\n",
    "            print(\" ✅\")\n",
    "        except Exception as e:\n",
    "            erros.append(ticker)\n",
    "            print(f\" ❌ (Erro: {e})\")\n",
    "    if not dados_detalhados:\n",
    "        print(\"\\n❌ NENHUM DADO FOI COLETADO COM SUCESSO. O arquivo CSV não será gerado.\")\n",
    "        return\n",
    "    df_resultado = pd.DataFrame.from_dict(dados_detalhados, orient=\"index\")\n",
    "    df_resultado.fillna(0, inplace=True)\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        df_resultado.to_csv(output_path)\n",
    "        print(f\"\\n✅ SUCESSO! Relatório salvo com sucesso em: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERRO INESPERADO AO SALVAR O ARQUIVO: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f857af",
   "metadata": {},
   "outputs": [],
   "source": [
    "    arquivo_input = r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\scanner_acoes_e_fundos_filtrado.csv\"\n",
    "    output_path = r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\relatorio_analise_b3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.py:\n",
    "\n",
    "df = load_data(r\"C:\\Users\\01701805\\Desktop\\Projetos GL\\finance-manager\\data\\relatorio_analise_b3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_dados = pd.read_excel(r'E:\\Github\\finance-manager\\datasets\\relatorio_completo_b3.xlsx')\n",
    "\n",
    "# print(df_dados.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
